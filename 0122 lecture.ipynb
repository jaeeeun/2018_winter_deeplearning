{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2499\n",
      "100 0.637709\n",
      "200 0.578444\n",
      "300 0.539152\n",
      "400 0.51158\n",
      "500 0.491054\n",
      "600 0.47491\n",
      "700 0.461593\n",
      "800 0.450167\n",
      "900 0.44005\n",
      "1000 0.430872\n",
      "1100 0.42239\n",
      "1200 0.414441\n",
      "1300 0.406915\n",
      "1400 0.399733\n",
      "1500 0.392842\n",
      "1600 0.386202\n",
      "1700 0.379783\n",
      "1800 0.373565\n",
      "1900 0.36753\n",
      "2000 0.361666\n",
      "2100 0.355963\n",
      "2200 0.350411\n",
      "2300 0.345005\n",
      "2400 0.339737\n",
      "2500 0.334603\n",
      "2600 0.329598\n",
      "2700 0.324717\n",
      "2800 0.319957\n",
      "2900 0.315313\n",
      "3000 0.310783\n",
      "3100 0.306362\n",
      "3200 0.302049\n",
      "3300 0.297838\n",
      "3400 0.293729\n",
      "3500 0.289717\n",
      "3600 0.285799\n",
      "3700 0.281974\n",
      "3800 0.278239\n",
      "3900 0.27459\n",
      "4000 0.271025\n",
      "4100 0.267543\n",
      "4200 0.26414\n",
      "4300 0.260814\n",
      "4400 0.257563\n",
      "4500 0.254386\n",
      "4600 0.251279\n",
      "4700 0.248241\n",
      "4800 0.24527\n",
      "4900 0.242364\n",
      "5000 0.239521\n",
      "5100 0.236739\n",
      "5200 0.234017\n",
      "5300 0.231353\n",
      "5400 0.228745\n",
      "5500 0.226192\n",
      "5600 0.223692\n",
      "5700 0.221244\n",
      "5800 0.218846\n",
      "5900 0.216496\n",
      "6000 0.214195\n",
      "6100 0.211939\n",
      "6200 0.209729\n",
      "6300 0.207562\n",
      "6400 0.205438\n",
      "6500 0.203355\n",
      "6600 0.201313\n",
      "6700 0.199309\n",
      "6800 0.197344\n",
      "6900 0.195416\n",
      "7000 0.193525\n",
      "7100 0.191668\n",
      "7200 0.189846\n",
      "7300 0.188058\n",
      "7400 0.186302\n",
      "7500 0.184578\n",
      "7600 0.182885\n",
      "7700 0.181222\n",
      "7800 0.179588\n",
      "7900 0.177984\n",
      "8000 0.176407\n",
      "8100 0.174857\n",
      "8200 0.173335\n",
      "8300 0.171838\n",
      "8400 0.170366\n",
      "8500 0.16892\n",
      "8600 0.167497\n",
      "8700 0.166098\n",
      "8800 0.164722\n",
      "8900 0.163369\n",
      "9000 0.162037\n",
      "9100 0.160727\n",
      "9200 0.159438\n",
      "9300 0.158169\n",
      "9400 0.156921\n",
      "9500 0.155692\n",
      "9600 0.154482\n",
      "9700 0.15329\n",
      "9800 0.152117\n",
      "9900 0.150962\n",
      "\n",
      "hypotheisis(예측값):\n",
      " [[ 0.03088355]\n",
      " [ 0.1590406 ]\n",
      " [ 0.30555221]\n",
      " [ 0.78106964]\n",
      " [ 0.9393779 ]\n",
      " [ 0.98010272]] \n",
      "correct(실제값):\n",
      " [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# 지도학습\n",
    "# 데이터와 데이터에 대한 결과를 알고있음 \n",
    "# 학습용 데이터를 이용하여 예측을 해보는 것\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#학습률 값\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "x_data=[[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data=[[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=[None,2])\n",
    "Y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "# 기울기 W와 바이어스 b의 값을 임의로 정한다\n",
    "W=tf.Variable(tf.random_normal([2,1]),name='weight')\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "#시그노이드함수구하기 - matuml : 행렬곱\n",
    "hypothesis=tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "#오차구하는 함수 구하기\n",
    "cost=-tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "#학습률에 대하여 오차를 최소로하는 값 찾기\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "\n",
    "predicted = tf.cast (hypothesis > 0.5 , dtype = tf.float32)\n",
    "\n",
    "#원래 데이터를 넣고 정확도를 측정\n",
    "#실제값과 같은지,안같은지\n",
    "accuracy = tf.reduce_mean (tf.cast (tf.equal (predicted , Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "# 학습 시작\n",
    "sess = tf.Session () \n",
    "sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "\n",
    "\n",
    "# 학습을 시키는 과정\n",
    "for i in range (10000): \n",
    "    cost_val,_=sess.run([cost,train],feed_dict={X:x_data,Y:y_data})\n",
    "    if i % 100 == 0:\n",
    "        print (i, cost_val )\n",
    "\n",
    "        \n",
    "# Accruacy report\n",
    "h, c, a= sess.run ([ hypothesis , predicted , accuracy ], feed_dict ={ X: x_data , Y: y_data }) \n",
    "\n",
    "print(\"\\nhypotheisis(예측값):\\n\",h,\"\\ncorrect(실제값):\\n\",c,\"\\nAccuracy:\\n\",a)\n",
    "\n",
    "\n",
    "# 횟수를 적게하고 Lerning rate를 높이는게 효과가 더 좋다\n",
    "# 돌려보면 cost_Val이 더 작아짐 [학습이 잘됨]\n",
    "# 조절해서 최적의 학습효과를 낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.735198\n",
      "200 0.565984\n",
      "400 0.515064\n",
      "600 0.495386\n",
      "800 0.486178\n",
      "1000 0.481209\n",
      "1200 0.478258\n",
      "1400 0.476386\n",
      "1600 0.475142\n",
      "1800 0.474285\n",
      "2000 0.473677\n",
      "2200 0.473236\n",
      "2400 0.472908\n",
      "2600 0.472662\n",
      "2800 0.472472\n",
      "3000 0.472325\n",
      "3200 0.472209\n",
      "3400 0.472117\n",
      "3600 0.472042\n",
      "3800 0.471982\n",
      "4000 0.471932\n",
      "4200 0.471891\n",
      "4400 0.471858\n",
      "4600 0.471829\n",
      "4800 0.471806\n",
      "5000 0.471786\n",
      "5200 0.471769\n",
      "5400 0.471755\n",
      "5600 0.471743\n",
      "5800 0.471733\n",
      "6000 0.471724\n",
      "6200 0.471717\n",
      "6400 0.47171\n",
      "6600 0.471705\n",
      "6800 0.4717\n",
      "7000 0.471696\n",
      "7200 0.471693\n",
      "7400 0.471689\n",
      "7600 0.471687\n",
      "7800 0.471685\n",
      "8000 0.471683\n",
      "8200 0.471681\n",
      "8400 0.47168\n",
      "8600 0.471679\n",
      "8800 0.471678\n",
      "9000 0.471677\n",
      "9200 0.471676\n",
      "9400 0.471675\n",
      "9600 0.471675\n",
      "9800 0.471674\n",
      "10000 0.471674\n",
      "10200 0.471673\n",
      "10400 0.471673\n",
      "10600 0.471673\n",
      "10800 0.471672\n",
      "11000 0.471672\n",
      "11200 0.471672\n",
      "11400 0.471672\n",
      "11600 0.471672\n",
      "11800 0.471672\n",
      "12000 0.471671\n",
      "12200 0.471671\n",
      "12400 0.471671\n",
      "12600 0.471671\n",
      "12800 0.471671\n",
      "13000 0.471671\n",
      "13200 0.471671\n",
      "13400 0.471671\n",
      "13600 0.471671\n",
      "13800 0.471671\n",
      "14000 0.471671\n",
      "14200 0.471671\n",
      "14400 0.471671\n",
      "14600 0.471671\n",
      "14800 0.471671\n",
      "15000 0.471671\n",
      "15200 0.471671\n",
      "15400 0.471671\n",
      "15600 0.471671\n",
      "15800 0.471671\n",
      "16000 0.471671\n",
      "16200 0.471671\n",
      "16400 0.471671\n",
      "16600 0.471671\n",
      "16800 0.471671\n",
      "17000 0.471671\n",
      "17200 0.471671\n",
      "17400 0.471671\n",
      "17600 0.471671\n",
      "17800 0.471671\n",
      "18000 0.471671\n",
      "18200 0.471671\n",
      "18400 0.471671\n",
      "18600 0.471671\n",
      "18800 0.471671\n",
      "19000 0.471671\n",
      "19200 0.471671\n",
      "19400 0.471671\n",
      "19600 0.471671\n",
      "19800 0.471671\n",
      "20000 0.471671\n",
      "20200 0.471671\n",
      "20400 0.471671\n",
      "20600 0.471671\n",
      "20800 0.471671\n",
      "21000 0.471671\n",
      "21200 0.471671\n",
      "21400 0.471671\n",
      "21600 0.471671\n",
      "21800 0.471671\n",
      "22000 0.471671\n",
      "22200 0.471671\n",
      "22400 0.471671\n",
      "22600 0.471671\n",
      "22800 0.471671\n",
      "23000 0.471671\n",
      "23200 0.471671\n",
      "23400 0.471671\n",
      "23600 0.471671\n",
      "23800 0.471671\n",
      "24000 0.471671\n",
      "24200 0.471671\n",
      "24400 0.471671\n",
      "24600 0.471671\n",
      "24800 0.471671\n",
      "25000 0.471671\n",
      "25200 0.471671\n",
      "25400 0.471671\n",
      "25600 0.471671\n",
      "25800 0.471671\n",
      "26000 0.471671\n",
      "26200 0.471671\n",
      "26400 0.471671\n",
      "26600 0.471671\n",
      "26800 0.471671\n",
      "27000 0.471671\n",
      "27200 0.471671\n",
      "27400 0.471671\n",
      "27600 0.471671\n",
      "27800 0.471671\n",
      "28000 0.471671\n",
      "28200 0.471671\n",
      "28400 0.471671\n",
      "28600 0.471671\n",
      "28800 0.471671\n",
      "29000 0.471671\n",
      "29200 0.471671\n",
      "29400 0.471671\n",
      "29600 0.471671\n",
      "29800 0.471671\n",
      "30000 0.471671\n",
      "30200 0.471671\n",
      "30400 0.471671\n",
      "30600 0.471671\n",
      "30800 0.471671\n",
      "31000 0.471671\n",
      "31200 0.471671\n",
      "31400 0.471671\n",
      "31600 0.471671\n",
      "31800 0.471671\n",
      "32000 0.471671\n",
      "32200 0.471671\n",
      "32400 0.471671\n",
      "32600 0.471671\n",
      "32800 0.471671\n",
      "33000 0.471671\n",
      "33200 0.471671\n",
      "33400 0.471671\n",
      "33600 0.471671\n",
      "33800 0.471671\n",
      "34000 0.471671\n",
      "34200 0.471671\n",
      "34400 0.471671\n",
      "34600 0.471671\n",
      "34800 0.471671\n",
      "35000 0.471671\n",
      "35200 0.471671\n",
      "35400 0.471671\n",
      "35600 0.471671\n",
      "35800 0.471671\n",
      "36000 0.471671\n",
      "36200 0.471671\n",
      "36400 0.471671\n",
      "36600 0.471671\n",
      "36800 0.471671\n",
      "37000 0.471671\n",
      "37200 0.471671\n",
      "37400 0.471671\n",
      "37600 0.471671\n",
      "37800 0.471671\n",
      "38000 0.471671\n",
      "38200 0.471671\n",
      "38400 0.471671\n",
      "38600 0.471671\n",
      "38800 0.471671\n",
      "39000 0.471671\n",
      "39200 0.471671\n",
      "39400 0.471671\n",
      "39600 0.471671\n",
      "39800 0.471671\n",
      "40000 0.471671\n",
      "40200 0.471671\n",
      "40400 0.471671\n",
      "40600 0.471671\n",
      "40800 0.471671\n",
      "41000 0.471671\n",
      "41200 0.471671\n",
      "41400 0.471671\n",
      "41600 0.471671\n",
      "41800 0.471671\n",
      "42000 0.471671\n",
      "42200 0.471671\n",
      "42400 0.471671\n",
      "42600 0.471671\n",
      "42800 0.471671\n",
      "43000 0.471671\n",
      "43200 0.471671\n",
      "43400 0.471671\n",
      "43600 0.471671\n",
      "43800 0.471671\n",
      "44000 0.471671\n",
      "44200 0.471671\n",
      "44400 0.471671\n",
      "44600 0.471671\n",
      "44800 0.471671\n",
      "45000 0.471671\n",
      "45200 0.471671\n",
      "45400 0.471671\n",
      "45600 0.471671\n",
      "45800 0.471671\n",
      "46000 0.471671\n",
      "46200 0.471671\n",
      "46400 0.471671\n",
      "46600 0.471671\n",
      "46800 0.471671\n",
      "47000 0.471671\n",
      "47200 0.471671\n",
      "47400 0.471671\n",
      "47600 0.471671\n",
      "47800 0.471671\n",
      "48000 0.471671\n",
      "48200 0.471671\n",
      "48400 0.471671\n",
      "48600 0.471671\n",
      "48800 0.471671\n",
      "49000 0.471671\n",
      "49200 0.471671\n",
      "49400 0.471671\n",
      "49600 0.471671\n",
      "49800 0.471671\n",
      "50000 0.471671\n",
      "\n",
      "Hypothesis:  [[ 0.35394058]\n",
      " [ 0.95650119]\n",
      " [ 0.19471624]\n",
      " [ 0.96234804]\n",
      " [ 0.0689533 ]\n",
      " [ 0.83401799]\n",
      " [ 0.95318323]\n",
      " [ 0.57315814]\n",
      " [ 0.17770842]\n",
      " [ 0.593678  ]\n",
      " [ 0.75417858]\n",
      " [ 0.10995155]\n",
      " [ 0.27329525]\n",
      " [ 0.19024079]\n",
      " [ 0.7813217 ]\n",
      " [ 0.38072348]\n",
      " [ 0.79497266]\n",
      " [ 0.75799334]\n",
      " [ 0.81938535]\n",
      " [ 0.57672077]\n",
      " [ 0.72249246]\n",
      " [ 0.05970541]\n",
      " [ 0.72217554]\n",
      " [ 0.67680693]\n",
      " [ 0.28615659]\n",
      " [ 0.9623549 ]\n",
      " [ 0.61966008]\n",
      " [ 0.70849633]\n",
      " [ 0.7024895 ]\n",
      " [ 0.40013188]\n",
      " [ 0.96955925]\n",
      " [ 0.9523955 ]\n",
      " [ 0.64604259]\n",
      " [ 0.87163645]\n",
      " [ 0.3502022 ]\n",
      " [ 0.6880464 ]\n",
      " [ 0.83759689]\n",
      " [ 0.51410794]\n",
      " [ 0.32590237]\n",
      " [ 0.31963679]\n",
      " [ 0.9135291 ]\n",
      " [ 0.09757386]\n",
      " [ 0.37909582]\n",
      " [ 0.02296653]\n",
      " [ 0.5451104 ]\n",
      " [ 0.96331346]\n",
      " [ 0.68399143]\n",
      " [ 0.72935957]\n",
      " [ 0.97153509]\n",
      " [ 0.94923884]\n",
      " [ 0.95979279]\n",
      " [ 0.18685062]\n",
      " [ 0.27655226]\n",
      " [ 0.97982806]\n",
      " [ 0.112786  ]\n",
      " [ 0.43472332]\n",
      " [ 0.08561927]\n",
      " [ 0.6599583 ]\n",
      " [ 0.89723521]\n",
      " [ 0.49564821]\n",
      " [ 0.9783774 ]\n",
      " [ 0.71841711]\n",
      " [ 0.67514139]\n",
      " [ 0.89777088]\n",
      " [ 0.66020185]\n",
      " [ 0.57582784]\n",
      " [ 0.97871518]\n",
      " [ 0.72917348]\n",
      " [ 0.8688519 ]\n",
      " [ 0.66692507]\n",
      " [ 0.21831307]\n",
      " [ 0.73457301]\n",
      " [ 0.94943678]\n",
      " [ 0.94710439]\n",
      " [ 0.931508  ]\n",
      " [ 0.80504882]\n",
      " [ 0.29687318]\n",
      " [ 0.90702873]\n",
      " [ 0.91767573]\n",
      " [ 0.9437086 ]\n",
      " [ 0.91413307]\n",
      " [ 0.88238978]\n",
      " [ 0.31133604]\n",
      " [ 0.84013641]\n",
      " [ 0.53337973]\n",
      " [ 0.86842197]\n",
      " [ 0.33330074]\n",
      " [ 0.93148267]\n",
      " [ 0.97270739]\n",
      " [ 0.79303759]\n",
      " [ 0.78799242]\n",
      " [ 0.73321539]\n",
      " [ 0.76875657]\n",
      " [ 0.53079343]\n",
      " [ 0.92573625]\n",
      " [ 0.98815221]\n",
      " [ 0.90907317]\n",
      " [ 0.51422882]\n",
      " [ 0.16432148]\n",
      " [ 0.66308016]\n",
      " [ 0.76932013]\n",
      " [ 0.97834903]\n",
      " [ 0.7767868 ]\n",
      " [ 0.75635093]\n",
      " [ 0.96795583]\n",
      " [ 0.65243882]\n",
      " [ 0.93284637]\n",
      " [ 0.84622526]\n",
      " [ 0.41326809]\n",
      " [ 0.25716785]\n",
      " [ 0.95703948]\n",
      " [ 0.90466779]\n",
      " [ 0.32932639]\n",
      " [ 0.47894868]\n",
      " [ 0.64543265]\n",
      " [ 0.85354006]\n",
      " [ 0.89880317]\n",
      " [ 0.95723563]\n",
      " [ 0.05396778]\n",
      " [ 0.73062539]\n",
      " [ 0.87509298]\n",
      " [ 0.69803447]\n",
      " [ 0.67050725]\n",
      " [ 0.61054534]\n",
      " [ 0.6201511 ]\n",
      " [ 0.83445197]\n",
      " [ 0.84337801]\n",
      " [ 0.71994281]\n",
      " [ 0.43459079]\n",
      " [ 0.36035624]\n",
      " [ 0.32065532]\n",
      " [ 0.79588008]\n",
      " [ 0.96454173]\n",
      " [ 0.81319505]\n",
      " [ 0.81862682]\n",
      " [ 0.88073814]\n",
      " [ 0.48777488]\n",
      " [ 0.80550587]\n",
      " [ 0.83583009]\n",
      " [ 0.73332733]\n",
      " [ 0.8779797 ]\n",
      " [ 0.65700436]\n",
      " [ 0.4953467 ]\n",
      " [ 0.72792238]\n",
      " [ 0.95047468]\n",
      " [ 0.76838166]\n",
      " [ 0.42910847]\n",
      " [ 0.95946562]\n",
      " [ 0.60045284]\n",
      " [ 0.85753798]\n",
      " [ 0.2154655 ]\n",
      " [ 0.31032172]\n",
      " [ 0.04450164]\n",
      " [ 0.13757102]\n",
      " [ 0.9327693 ]\n",
      " [ 0.90153766]\n",
      " [ 0.96467787]\n",
      " [ 0.05510473]\n",
      " [ 0.56691444]\n",
      " [ 0.78185016]\n",
      " [ 0.54514378]\n",
      " [ 0.89481157]\n",
      " [ 0.46609718]\n",
      " [ 0.84017098]\n",
      " [ 0.57194626]\n",
      " [ 0.68145072]\n",
      " [ 0.75792474]\n",
      " [ 0.91245914]\n",
      " [ 0.8388989 ]\n",
      " [ 0.56854135]\n",
      " [ 0.91813308]\n",
      " [ 0.86335498]\n",
      " [ 0.96838623]\n",
      " [ 0.15477003]\n",
      " [ 0.8811391 ]\n",
      " [ 0.11099521]\n",
      " [ 0.27817157]\n",
      " [ 0.35854116]\n",
      " [ 0.94712818]\n",
      " [ 0.6220668 ]\n",
      " [ 0.94972754]\n",
      " [ 0.9484539 ]\n",
      " [ 0.64099753]\n",
      " [ 0.07081862]\n",
      " [ 0.13502435]\n",
      " [ 0.67353737]\n",
      " [ 0.79851884]\n",
      " [ 0.6477375 ]\n",
      " [ 0.89235353]\n",
      " [ 0.61110944]\n",
      " [ 0.3148098 ]\n",
      " [ 0.08914796]\n",
      " [ 0.93491435]\n",
      " [ 0.30518952]\n",
      " [ 0.91186339]\n",
      " [ 0.93053055]\n",
      " [ 0.71271086]\n",
      " [ 0.59745812]\n",
      " [ 0.65692216]\n",
      " [ 0.52969354]\n",
      " [ 0.75854659]\n",
      " [ 0.97300369]\n",
      " [ 0.76055509]\n",
      " [ 0.87803578]\n",
      " [ 0.06575713]\n",
      " [ 0.30350608]\n",
      " [ 0.91861171]\n",
      " [ 0.1448264 ]\n",
      " [ 0.9585194 ]\n",
      " [ 0.20723167]\n",
      " [ 0.21400853]\n",
      " [ 0.32252401]\n",
      " [ 0.73522818]\n",
      " [ 0.12015518]\n",
      " [ 0.73978579]\n",
      " [ 0.73308486]\n",
      " [ 0.86610097]\n",
      " [ 0.64892185]\n",
      " [ 0.07909914]\n",
      " [ 0.3547366 ]\n",
      " [ 0.76612645]\n",
      " [ 0.4809888 ]\n",
      " [ 0.95280743]\n",
      " [ 0.95581377]\n",
      " [ 0.73194945]\n",
      " [ 0.2349073 ]\n",
      " [ 0.01637288]\n",
      " [ 0.57461673]\n",
      " [ 0.27963582]\n",
      " [ 0.33644632]\n",
      " [ 0.97656494]\n",
      " [ 0.63172251]\n",
      " [ 0.96948302]\n",
      " [ 0.12478831]\n",
      " [ 0.0728927 ]\n",
      " [ 0.24427105]\n",
      " [ 0.87688524]\n",
      " [ 0.93991846]\n",
      " [ 0.90707999]\n",
      " [ 0.66858566]\n",
      " [ 0.65151477]\n",
      " [ 0.52297431]\n",
      " [ 0.10810128]\n",
      " [ 0.56805646]\n",
      " [ 0.05934512]\n",
      " [ 0.54504955]\n",
      " [ 0.91224808]\n",
      " [ 0.67309719]\n",
      " [ 0.78460228]\n",
      " [ 0.97535002]\n",
      " [ 0.83514798]\n",
      " [ 0.79982364]\n",
      " [ 0.76738584]\n",
      " [ 0.78705215]\n",
      " [ 0.89095974]\n",
      " [ 0.28339744]\n",
      " [ 0.29982489]\n",
      " [ 0.50169641]\n",
      " [ 0.85550785]\n",
      " [ 0.64644891]\n",
      " [ 0.69302702]\n",
      " [ 0.83086157]\n",
      " [ 0.24722415]\n",
      " [ 0.40162218]\n",
      " [ 0.65485042]\n",
      " [ 0.63869172]\n",
      " [ 0.35721755]\n",
      " [ 0.93248761]\n",
      " [ 0.85386395]\n",
      " [ 0.95794082]\n",
      " [ 0.56619424]\n",
      " [ 0.76575565]\n",
      " [ 0.85356098]\n",
      " [ 0.85429877]\n",
      " [ 0.76344967]\n",
      " [ 0.89446259]\n",
      " [ 0.27562243]\n",
      " [ 0.54346925]\n",
      " [ 0.70144969]\n",
      " [ 0.3652854 ]\n",
      " [ 0.88236529]\n",
      " [ 0.23385659]\n",
      " [ 0.54664207]\n",
      " [ 0.96223426]\n",
      " [ 0.79261446]\n",
      " [ 0.88768941]\n",
      " [ 0.6537503 ]\n",
      " [ 0.394577  ]\n",
      " [ 0.52936226]\n",
      " [ 0.38612574]\n",
      " [ 0.35336056]\n",
      " [ 0.6652118 ]\n",
      " [ 0.66704792]\n",
      " [ 0.64372516]\n",
      " [ 0.71690553]\n",
      " [ 0.14453997]\n",
      " [ 0.63696796]\n",
      " [ 0.93661511]\n",
      " [ 0.41140234]\n",
      " [ 0.7217744 ]\n",
      " [ 0.74282557]\n",
      " [ 0.44167137]\n",
      " [ 0.7431336 ]\n",
      " [ 0.47609687]\n",
      " [ 0.69969523]\n",
      " [ 0.94005597]\n",
      " [ 0.62606037]\n",
      " [ 0.7059015 ]\n",
      " [ 0.85630906]\n",
      " [ 0.55594879]\n",
      " [ 0.86148709]\n",
      " [ 0.97409135]\n",
      " [ 0.25626728]\n",
      " [ 0.76722705]\n",
      " [ 0.23805465]\n",
      " [ 0.77824801]\n",
      " [ 0.84687412]\n",
      " [ 0.73277891]\n",
      " [ 0.37842894]\n",
      " [ 0.8031075 ]\n",
      " [ 0.7587238 ]\n",
      " [ 0.72521698]\n",
      " [ 0.11773727]\n",
      " [ 0.80508095]\n",
      " [ 0.87812573]\n",
      " [ 0.64060771]\n",
      " [ 0.95209765]\n",
      " [ 0.12852621]\n",
      " [ 0.80793691]\n",
      " [ 0.96894473]\n",
      " [ 0.1064553 ]\n",
      " [ 0.44190806]\n",
      " [ 0.73814291]\n",
      " [ 0.27065238]\n",
      " [ 0.11280257]\n",
      " [ 0.87310547]\n",
      " [ 0.94979429]\n",
      " [ 0.89018267]\n",
      " [ 0.66199481]\n",
      " [ 0.68597376]\n",
      " [ 0.55254924]\n",
      " [ 0.7293238 ]\n",
      " [ 0.87362897]\n",
      " [ 0.96130401]\n",
      " [ 0.73926592]\n",
      " [ 0.78053021]\n",
      " [ 0.63377053]\n",
      " [ 0.96376115]\n",
      " [ 0.95954478]\n",
      " [ 0.73631316]\n",
      " [ 0.26561791]\n",
      " [ 0.64228821]\n",
      " [ 0.24413604]\n",
      " [ 0.7838707 ]\n",
      " [ 0.12070414]\n",
      " [ 0.16597876]\n",
      " [ 0.39802569]\n",
      " [ 0.75963348]\n",
      " [ 0.31139061]\n",
      " [ 0.51484096]\n",
      " [ 0.83899111]\n",
      " [ 0.71215343]\n",
      " [ 0.9068538 ]\n",
      " [ 0.97403359]\n",
      " [ 0.80854076]\n",
      " [ 0.05569741]\n",
      " [ 0.40821755]\n",
      " [ 0.84603721]\n",
      " [ 0.86203098]\n",
      " [ 0.61532694]\n",
      " [ 0.21939066]\n",
      " [ 0.92971683]\n",
      " [ 0.90358162]\n",
      " [ 0.1702459 ]\n",
      " [ 0.63183212]\n",
      " [ 0.87237537]\n",
      " [ 0.91116911]\n",
      " [ 0.8917796 ]\n",
      " [ 0.93558693]\n",
      " [ 0.91057533]\n",
      " [ 0.94004238]\n",
      " [ 0.70579439]\n",
      " [ 0.62608474]\n",
      " [ 0.54537094]\n",
      " [ 0.8597765 ]\n",
      " [ 0.89888436]\n",
      " [ 0.13033055]\n",
      " [ 0.84477049]\n",
      " [ 0.91743505]\n",
      " [ 0.29675806]\n",
      " [ 0.61469626]\n",
      " [ 0.90335697]\n",
      " [ 0.5178653 ]\n",
      " [ 0.96251923]\n",
      " [ 0.17430232]\n",
      " [ 0.87117243]\n",
      " [ 0.62176782]\n",
      " [ 0.9223175 ]\n",
      " [ 0.2851209 ]\n",
      " [ 0.57210433]\n",
      " [ 0.77899504]\n",
      " [ 0.86915809]\n",
      " [ 0.0743558 ]\n",
      " [ 0.12716663]\n",
      " [ 0.73932749]\n",
      " [ 0.8339377 ]\n",
      " [ 0.36656275]\n",
      " [ 0.81374437]\n",
      " [ 0.40409714]\n",
      " [ 0.29873836]\n",
      " [ 0.89254051]\n",
      " [ 0.39792514]\n",
      " [ 0.96872407]\n",
      " [ 0.84301901]\n",
      " [ 0.62629986]\n",
      " [ 0.94654238]\n",
      " [ 0.61155856]\n",
      " [ 0.81409234]\n",
      " [ 0.22126986]\n",
      " [ 0.19103415]\n",
      " [ 0.78005207]\n",
      " [ 0.30946746]\n",
      " [ 0.43270469]\n",
      " [ 0.92267239]\n",
      " [ 0.94395703]\n",
      " [ 0.9380008 ]\n",
      " [ 0.96909213]\n",
      " [ 0.75846916]\n",
      " [ 0.93244469]\n",
      " [ 0.24676009]\n",
      " [ 0.31615207]\n",
      " [ 0.49241501]\n",
      " [ 0.97336394]\n",
      " [ 0.64407706]\n",
      " [ 0.13647726]\n",
      " [ 0.94791204]\n",
      " [ 0.81496716]\n",
      " [ 0.62448311]\n",
      " [ 0.81605405]\n",
      " [ 0.00451395]\n",
      " [ 0.94944793]\n",
      " [ 0.80334449]\n",
      " [ 0.76128542]\n",
      " [ 0.78253227]\n",
      " [ 0.98275775]\n",
      " [ 0.67420578]\n",
      " [ 0.76388514]\n",
      " [ 0.81704694]\n",
      " [ 0.83666503]\n",
      " [ 0.11381542]\n",
      " [ 0.6368165 ]\n",
      " [ 0.93624538]\n",
      " [ 0.63765067]\n",
      " [ 0.81589246]\n",
      " [ 0.97604543]\n",
      " [ 0.875633  ]\n",
      " [ 0.93189162]\n",
      " [ 0.67495215]\n",
      " [ 0.81210047]\n",
      " [ 0.95756626]\n",
      " [ 0.73977798]\n",
      " [ 0.66263849]\n",
      " [ 0.18958665]\n",
      " [ 0.39884263]\n",
      " [ 0.50452834]\n",
      " [ 0.55497044]\n",
      " [ 0.59158736]\n",
      " [ 0.82276058]\n",
      " [ 0.6251356 ]\n",
      " [ 0.82391787]\n",
      " [ 0.88167095]\n",
      " [ 0.78969532]\n",
      " [ 0.71350026]\n",
      " [ 0.40640858]\n",
      " [ 0.61377007]\n",
      " [ 0.95500571]\n",
      " [ 0.86895084]\n",
      " [ 0.1452499 ]\n",
      " [ 0.32638243]\n",
      " [ 0.39254174]\n",
      " [ 0.04407366]\n",
      " [ 0.92950243]\n",
      " [ 0.12358428]\n",
      " [ 0.91196382]\n",
      " [ 0.92191362]\n",
      " [ 0.86494982]\n",
      " [ 0.69417596]\n",
      " [ 0.91953796]\n",
      " [ 0.35144049]\n",
      " [ 0.84208465]\n",
      " [ 0.96065199]\n",
      " [ 0.24920061]\n",
      " [ 0.4109875 ]\n",
      " [ 0.92329156]\n",
      " [ 0.89662063]\n",
      " [ 0.63912398]\n",
      " [ 0.82365108]\n",
      " [ 0.84159356]\n",
      " [ 0.87203401]\n",
      " [ 0.19685103]\n",
      " [ 0.76246762]\n",
      " [ 0.91227049]\n",
      " [ 0.7138676 ]\n",
      " [ 0.84807688]\n",
      " [ 0.73539871]\n",
      " [ 0.88493204]\n",
      " [ 0.91383535]\n",
      " [ 0.95006847]\n",
      " [ 0.54066736]\n",
      " [ 0.42059398]\n",
      " [ 0.81564492]\n",
      " [ 0.84826106]\n",
      " [ 0.98519784]\n",
      " [ 0.78957862]\n",
      " [ 0.70318478]\n",
      " [ 0.38140112]\n",
      " [ 0.72272563]\n",
      " [ 0.95670867]\n",
      " [ 0.97527063]\n",
      " [ 0.9241482 ]\n",
      " [ 0.71131116]\n",
      " [ 0.73897463]\n",
      " [ 0.81125236]\n",
      " [ 0.40386572]\n",
      " [ 0.81348532]\n",
      " [ 0.84682983]\n",
      " [ 0.9116621 ]\n",
      " [ 0.59757626]\n",
      " [ 0.79914421]\n",
      " [ 0.95108795]\n",
      " [ 0.46568039]\n",
      " [ 0.55238891]\n",
      " [ 0.64410615]\n",
      " [ 0.73084193]\n",
      " [ 0.71139175]\n",
      " [ 0.92575139]\n",
      " [ 0.94966668]\n",
      " [ 0.15234187]\n",
      " [ 0.05924686]\n",
      " [ 0.74683881]\n",
      " [ 0.49047193]\n",
      " [ 0.2491681 ]\n",
      " [ 0.87982428]\n",
      " [ 0.93007421]\n",
      " [ 0.79001784]\n",
      " [ 0.9541223 ]\n",
      " [ 0.92535025]\n",
      " [ 0.80869812]\n",
      " [ 0.85402763]\n",
      " [ 0.76911211]\n",
      " [ 0.46191874]\n",
      " [ 0.83590037]\n",
      " [ 0.62374902]\n",
      " [ 0.04823519]\n",
      " [ 0.91535521]\n",
      " [ 0.90679586]\n",
      " [ 0.78898579]\n",
      " [ 0.93774992]\n",
      " [ 0.86630499]\n",
      " [ 0.90261704]\n",
      " [ 0.54846472]\n",
      " [ 0.66906178]\n",
      " [ 0.92500871]\n",
      " [ 0.84563774]\n",
      " [ 0.87210572]\n",
      " [ 0.91407639]\n",
      " [ 0.62791777]\n",
      " [ 0.76538289]\n",
      " [ 0.84582156]\n",
      " [ 0.50255471]\n",
      " [ 0.56166744]\n",
      " [ 0.06249086]\n",
      " [ 0.19503735]\n",
      " [ 0.87384784]\n",
      " [ 0.6898576 ]\n",
      " [ 0.68815106]\n",
      " [ 0.5937416 ]\n",
      " [ 0.96153331]\n",
      " [ 0.38308981]\n",
      " [ 0.87886387]\n",
      " [ 0.21432389]\n",
      " [ 0.95047736]\n",
      " [ 0.25947526]\n",
      " [ 0.78265184]\n",
      " [ 0.58896261]\n",
      " [ 0.88611054]\n",
      " [ 0.58442795]\n",
      " [ 0.16648951]\n",
      " [ 0.79832548]\n",
      " [ 0.93701136]\n",
      " [ 0.29784018]\n",
      " [ 0.93281341]\n",
      " [ 0.92318082]\n",
      " [ 0.90859479]\n",
      " [ 0.8576594 ]\n",
      " [ 0.35064372]\n",
      " [ 0.25750548]\n",
      " [ 0.65538722]\n",
      " [ 0.10868666]\n",
      " [ 0.97497761]\n",
      " [ 0.25311145]\n",
      " [ 0.94856572]\n",
      " [ 0.88768768]\n",
      " [ 0.29751888]\n",
      " [ 0.14813808]\n",
      " [ 0.74291086]\n",
      " [ 0.36200991]\n",
      " [ 0.8968367 ]\n",
      " [ 0.80763543]\n",
      " [ 0.99113303]\n",
      " [ 0.61125422]\n",
      " [ 0.63612455]\n",
      " [ 0.80430198]\n",
      " [ 0.87793928]\n",
      " [ 0.04311742]\n",
      " [ 0.69933206]\n",
      " [ 0.8416366 ]\n",
      " [ 0.88129866]\n",
      " [ 0.70080251]\n",
      " [ 0.47494835]\n",
      " [ 0.61988908]\n",
      " [ 0.94002646]\n",
      " [ 0.6866619 ]\n",
      " [ 0.80830795]\n",
      " [ 0.86558408]\n",
      " [ 0.89667487]\n",
      " [ 0.8645708 ]\n",
      " [ 0.61641073]\n",
      " [ 0.85247189]\n",
      " [ 0.92673993]\n",
      " [ 0.6812619 ]\n",
      " [ 0.97950166]\n",
      " [ 0.85142475]\n",
      " [ 0.62090844]\n",
      " [ 0.51489288]\n",
      " [ 0.88198888]\n",
      " [ 0.8924709 ]\n",
      " [ 0.38498011]\n",
      " [ 0.67455977]\n",
      " [ 0.11715265]\n",
      " [ 0.60311788]\n",
      " [ 0.8491711 ]\n",
      " [ 0.96584821]\n",
      " [ 0.82661521]\n",
      " [ 0.73535043]\n",
      " [ 0.79092461]\n",
      " [ 0.90240645]\n",
      " [ 0.3570691 ]\n",
      " [ 0.95926166]\n",
      " [ 0.55475587]\n",
      " [ 0.88884479]\n",
      " [ 0.32109582]\n",
      " [ 0.03769723]\n",
      " [ 0.25377083]\n",
      " [ 0.28457543]\n",
      " [ 0.69161791]\n",
      " [ 0.85774219]\n",
      " [ 0.57630336]\n",
      " [ 0.78875017]\n",
      " [ 0.81356668]\n",
      " [ 0.46741921]\n",
      " [ 0.28197658]\n",
      " [ 0.92825693]\n",
      " [ 0.93826026]\n",
      " [ 0.26716354]\n",
      " [ 0.72510773]\n",
      " [ 0.12890649]\n",
      " [ 0.44699544]\n",
      " [ 0.75896639]\n",
      " [ 0.67164862]\n",
      " [ 0.93132406]\n",
      " [ 0.9893629 ]\n",
      " [ 0.08964415]\n",
      " [ 0.6599378 ]\n",
      " [ 0.65325755]\n",
      " [ 0.44577327]\n",
      " [ 0.72516179]\n",
      " [ 0.79928941]\n",
      " [ 0.90776259]\n",
      " [ 0.77616227]\n",
      " [ 0.378591  ]\n",
      " [ 0.76486391]\n",
      " [ 0.13210011]\n",
      " [ 0.63268006]\n",
      " [ 0.46291056]\n",
      " [ 0.95060414]\n",
      " [ 0.60435605]\n",
      " [ 0.51892221]\n",
      " [ 0.85696143]\n",
      " [ 0.7338962 ]\n",
      " [ 0.38127589]\n",
      " [ 0.75060463]\n",
      " [ 0.70192826]\n",
      " [ 0.27700183]\n",
      " [ 0.54664415]\n",
      " [ 0.9159326 ]\n",
      " [ 0.86707479]\n",
      " [ 0.58042431]\n",
      " [ 0.73582566]\n",
      " [ 0.24834226]\n",
      " [ 0.84776062]\n",
      " [ 0.53252649]\n",
      " [ 0.78496355]\n",
      " [ 0.30221373]\n",
      " [ 0.64593041]\n",
      " [ 0.88854671]\n",
      " [ 0.08569019]\n",
      " [ 0.23161545]\n",
      " [ 0.87466657]\n",
      " [ 0.81878948]\n",
      " [ 0.81714326]\n",
      " [ 0.94805473]\n",
      " [ 0.76966995]\n",
      " [ 0.68813127]\n",
      " [ 0.72417897]\n",
      " [ 0.84304786]\n",
      " [ 0.69373941]\n",
      " [ 0.8044098 ]\n",
      " [ 0.48764092]\n",
      " [ 0.51570648]\n",
      " [ 0.91244555]\n",
      " [ 0.82841432]\n",
      " [ 0.7322824 ]\n",
      " [ 0.17750929]\n",
      " [ 0.89758235]\n",
      " [ 0.89316803]\n",
      " [ 0.84457576]\n",
      " [ 0.72515869]\n",
      " [ 0.92317575]\n",
      " [ 0.8586604 ]\n",
      " [ 0.78495401]\n",
      " [ 0.33820915]\n",
      " [ 0.89144832]\n",
      " [ 0.9264586 ]\n",
      " [ 0.35409972]\n",
      " [ 0.10391944]\n",
      " [ 0.78684026]\n",
      " [ 0.29653871]\n",
      " [ 0.78060466]\n",
      " [ 0.20367521]\n",
      " [ 0.4488377 ]\n",
      " [ 0.43084282]\n",
      " [ 0.76400483]\n",
      " [ 0.90462875]\n",
      " [ 0.08047345]\n",
      " [ 0.33650926]\n",
      " [ 0.61381245]\n",
      " [ 0.53623545]\n",
      " [ 0.49290001]\n",
      " [ 0.81393325]\n",
      " [ 0.11605769]\n",
      " [ 0.93908   ]\n",
      " [ 0.09305704]\n",
      " [ 0.91332799]\n",
      " [ 0.76192731]\n",
      " [ 0.71222371]\n",
      " [ 0.86651433]\n",
      " [ 0.73257428]\n",
      " [ 0.92897284]] \n",
      "Crrect(Y):  [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:  0.769433\n"
     ]
    }
   ],
   "source": [
    "#예제2 당뇨병 분류하기\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "LEARNING_RATE=0.1\n",
    "X_DATA_COLS=8\n",
    "\n",
    "xy = np.loadtxt( \"data-03-diabetes.csv\", delimiter =\",\",dtype =np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "\n",
    "# placeholdersforatensorthatwillbealwaysfed.\n",
    "X= tf.placeholder(tf.float32, shape=[None, X_DATA_COLS])\n",
    "Y= tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W= tf.Variable(tf.random_normal([X_DATA_COLS,1]), name= 'weight')\n",
    "b= tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "# Hypothesisusingsigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X,W) +b))\n",
    "hypothesis= tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "#cost/lossfunction\n",
    "cost= -tf.reduce_mean(Y* tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train= tf.train.GradientDescentOptimizer(learning_rate= LEARNING_RATE).minimize(cost)\n",
    "\n",
    "# Accuracycomputation\n",
    "# Trueifhypothesis> 0.5 else false\n",
    "predicted= tf.cast(hypothesis> 0.5, dtype= tf.float32)\n",
    "accuracy= tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "#Launchgraphsess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(50001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if i % 200 == 0:\n",
    "        print(i, cost_val)\n",
    "\n",
    "# Accruacyreport\n",
    "h, c, a= sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data,Y:y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCrrect(Y): \", c , \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, FIFOQueue '_0_filename_queue' is closed.\n",
      "\t [[Node: filename_queue/filename_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](filename_queue, filename_queue/Identity)]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_30_batch_14/fifo_queue' is closed and has insufficient elements (requested 20, current size 0)\n\t [[Node: batch_14 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_14/fifo_queue, batch_14/n)]]\n\nCaused by op 'batch_14', defined at:\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-63-0cd4a077185e>\", line 18, in <module>\n    batch_size= CONST_BATCH_SIZE)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 927, in batch\n    name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 722, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 464, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 2417, in _queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_30_batch_14/fifo_queue' is closed and has insufficient elements (requested 20, current size 0)\n\t [[Node: batch_14 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_14/fifo_queue, batch_14/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_30_batch_14/fifo_queue' is closed and has insufficient elements (requested 20, current size 0)\n\t [[Node: batch_14 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_14/fifo_queue, batch_14/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0cd4a077185e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_x_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mcost_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_30_batch_14/fifo_queue' is closed and has insufficient elements (requested 20, current size 0)\n\t [[Node: batch_14 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_14/fifo_queue, batch_14/n)]]\n\nCaused by op 'batch_14', defined at:\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-63-0cd4a077185e>\", line 18, in <module>\n    batch_size= CONST_BATCH_SIZE)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 927, in batch\n    name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 722, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 464, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 2417, in _queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_30_batch_14/fifo_queue' is closed and has insufficient elements (requested 20, current size 0)\n\t [[Node: batch_14 = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch_14/fifo_queue, batch_14/n)]]\n"
     ]
    }
   ],
   "source": [
    "#예제3 오류 못찾음\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "CONST_BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.01\n",
    "X_DATA_COLS = 8\n",
    "\n",
    "filename_queue= tf.train.string_input_producer(['data-03-diabetes.csv'])\n",
    "\n",
    "reader= tf.TextLineReader()\n",
    "key, value= reader.read(filename_queue)\n",
    "\n",
    "# Defaultvalues, incaseemptycolumns. Alsospecifiesthetypeof thedecoderesult.\n",
    "\n",
    "record_defaults= [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]\n",
    "xy= tf.decode_csv(value, record_defaults= record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch= tf.train.batch([xy[0: -1], xy[-1:]], \n",
    "                                             batch_size= CONST_BATCH_SIZE)\n",
    "\n",
    "# placeholdersforatensorthatwillbealwaysfed.\n",
    "\n",
    "X= tf.placeholder(tf.float32, shape=[None, X_DATA_COLS])\n",
    "Y= tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W= tf.Variable(tf.random_normal([X_DATA_COLS,1]), name= 'weight')\n",
    "b= tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "# Hypothesisusingsigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X,W) +b))\n",
    "\n",
    "hypothesis= tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "#cost/lossfunction\n",
    "cost= -tf.reduce_mean(Y* tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train= tf.train.GradientDescentOptimizer(learning_rate= LEARNING_RATE).minimize(cost)\n",
    "\n",
    "# Accuracycomputation\n",
    "# Trueifhypothesis> 0.5 elsefalse\n",
    "\n",
    "predicted= tf.cast(hypothesis> 0.5, dtype= tf.float32)\n",
    "accuracy= tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch\n",
    "graphsess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer()) \n",
    "\n",
    "coord= tf.train.Coordinator()\n",
    "threads= tf.train.start_queue_runners(sess= sess, coord= coord)\n",
    "\n",
    "a_sum= 0;\n",
    "a_cnt= 0;\n",
    "\n",
    "for i in range(10001):\n",
    "    x_batch, y_batch= sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: x_batch, Y:y_batch})\n",
    "    h, c, a= sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_batch, Y: y_batch})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCrrect(Y): \", c, \"\\nAccuracy: \", a)\n",
    "    a_sum+= a\n",
    "    a_cnt+=1\n",
    "    if i % 200 == 0:\n",
    "        print(i, cost_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "\n",
    "# Accruacyreport\n",
    "print(\"\\nAccuracy: \", a_sum/a_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-c6ae22d30e4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_val\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"공부시간 : %d,과외횟수 : %d  \"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# 지도학습\n",
    "# 데이터와 데이터에 대한 결과를 알고있음 \n",
    "# 학습용 데이터를 이용하여 예측을 해보는 것\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#학습률 값\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "x_data=[[1,2],[1,1],[6,4],[8,6],[10,7],[12,8]]\n",
    "y_data=[[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=[None,2])\n",
    "Y=tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "# 기울기 W와 바이어스 b의 값을 임의로 정한다\n",
    "W=tf.Variable(tf.random_normal([2,1]),name='weight')\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "\n",
    "#시그노이드함수구하기 - matuml : 행렬곱\n",
    "hypothesis=tf.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "#오차구하는 함수 구하기\n",
    "cost=-tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "#학습률에 대하여 오차를 최소로하는 값 찾기\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "predicted = tf.cast (hypothesis > 0.5 , dtype = tf.float32)\n",
    "\n",
    "#원래 데이터를 넣고 정확도를 측정\n",
    "#실제값과 같은지,안같은지\n",
    "accuracy = tf.reduce_mean (tf.cast (tf.equal (predicted , Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "# 학습 시작\n",
    "sess = tf.Session () \n",
    "sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#추가\n",
    "\n",
    "\n",
    "\n",
    "for i in range (1000): \n",
    "    cost_val,_=sess.run([cost,train],feed_dict={X:x_data,Y:y_data})\n",
    "    if i % 100 == 0:\n",
    "        print (i, cost_val )\n",
    "        print(\"공부시간 : %d,과외횟수 : %d  \"%(x_data[:,0],x_data[:,1]))\n",
    "\n",
    "\n",
    "# Accruacy report\n",
    "h, c, a= sess.run ([ hypothesis , predicted , accuracy ], feed_dict ={ X: x_data , Y: y_data }) \n",
    "\n",
    "        \n",
    "new_x = np.array([3,6]).reshape(1,2)\n",
    "new_y=sess.run(hypothesis,feed_dict={X:new_x})\n",
    "\n",
    "    \n",
    "print(\"공부한시간 : %d,과외수업횟수 : %d\"%(new_x[:,0],new_x[:,1]))\n",
    "print(\"합격 가능성 : %6.2f%%\"%(new_y*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
